{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for downloading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "def download_image(image_url, directory, index):\n",
    "    \"\"\"\n",
    "    Downloads an image from a given URL into a specified directory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            file_path = os.path.join(directory, f'image_{index}.jpg')\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {image_url}: {e}\")\n",
    "\n",
    "def scrape_images(search_term, limit):\n",
    "    \"\"\"\n",
    "    Scrapes images from DuckDuckGo based on a search term up to a specified limit.\n",
    "    \"\"\"\n",
    "    # Initialize the Chrome driver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    # Go to DuckDuckGo's image search page\n",
    "    driver.get(f\"https://duckduckgo.com/?q={search_term}&iax=images&ia=images\")\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "\n",
    "    # Scroll the page to ensure that images are loaded\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)  # Wait for new images to load\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Find image elements on the page\n",
    "    images = driver.find_elements(By.CSS_SELECTOR, \"img.tile--img__img.js-lazyload\")\n",
    "    images = images[:limit]  # Limit the number of images to download\n",
    "\n",
    "    # Create a directory for the downloaded images\n",
    "    directory = f\"downloaded_images_{search_term.replace(' ', '_')}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Download the images\n",
    "    for index, image in enumerate(images):\n",
    "        image_url = image.get_attribute('src')\n",
    "        if image_url:\n",
    "            download_image(image_url, directory, index)\n",
    "\n",
    "    driver.quit()\n",
    "    print(f\"Finished downloading images to {directory}.\")\n",
    "\n",
    "# Example usage\n",
    "search_term = \"animal\"  # Specify the search term here\n",
    "limit = 200  # Specify the maximum number of images to download\n",
    "\n",
    "scrape_images(search_term, limit)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
